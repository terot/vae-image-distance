#!/usr/bin/env python

# Use a variational autoencoder to find closest matches is latent space.

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os
import math

import edward as ed
import numpy as np
import tensorflow as tf

from edward.util import Progbar
from scipy.misc import imsave

import lib.model as model
import lib.batch as batch
import lib.utils as utils

def get_args():
  parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
  parser.add_argument('--data_dir', type=str,
                      default='data', help="data directory")
  parser.add_argument('--dataset', help="dataset for training",
                      default="mnist", type=str)
  parser.add_argument('--dim_latent', type=int,
                      default=10, help="dimension of latent space")
  parser.add_argument('--batch_size', type=int,
                      default=128, help="batch size for training and sample generation")
  parser.add_argument('--n_matches', type=int,
                      default=10, help="output n closest matches")
  parser.add_argument('--n_samples', type=int,
                      default=50, help="output n test samples")
  parser.add_argument('--verbose', action="store_true",
                      help="Verbose printing")
  return parser.parse_args()

def main(args):
  if args.verbose:
    print("args: " + str(vars(args)))
    
  # Prepare output
  if not os.path.exists(utils.output_dir(args)):
    os.makedirs(utils.output_dir(args))

  # Data
  data = utils.load_data(args.dataset, utils.input_dir(args))
  data_generator = batch.generator(data["x_test"], args.batch_size)
     
  # Model
  m = model.Model(args.batch_size, args.dim_latent)
  tf.global_variables_initializer().run()

  # Load model
  saver = tf.train.Saver()
  sess = ed.get_session()
  saver.restore(sess, utils.model_checkpoint(args))

  # Generate latent distribution for each image
  print("Computing latent representations:")
  locs = np.empty([0,args.dim_latent])
  scales = np.empty([0,args.dim_latent])
  n_iter_per_epoch = data["x_test"].shape[0] // args.batch_size
  pbar = Progbar(n_iter_per_epoch)
  for t in range(1, n_iter_per_epoch + 1):
    pbar.update(t)
    x_batch = next(data_generator)
    [loc, scale] = sess.run([m.loc, m.scale], {m.x_ph: x_batch})
    loc = np.reshape(loc, (args.batch_size, args.dim_latent))
    scale = np.reshape(scale, (args.batch_size, args.dim_latent))
    locs = np.append(locs, loc, axis=0)
    scales = np.append(scales, scale, axis=0)

  # Find closest image for each image
  print("Exporting output:")
  n_images = locs.shape[0]
  pbar = Progbar(min(n_images, args.n_samples))
  for i in range(min(n_images, args.n_samples)):
    pbar.update(i)
    distances = list(map(lambda k: distance(locs[i], scales[i], locs[k], scales[k]), range(n_images)))
    best_matches = sorted(range(n_images), key=lambda k: distances[k])[1:args.n_matches]
    im = data["x_test"][i].reshape(28, 28)
    for k in best_matches:
      im = np.concatenate((im, data["x_test"][k].reshape(28, 28)), axis=1)
    imsave(os.path.join(utils.output_dir(args), '%d.png') % i, im)
  print("\nOutput samples saved in {}".format(utils.output_dir(args)))
  
# kl divergence
def distance(loc_a, scale_a, loc_b, scale_b):
  dim_hidden = loc_a.shape[0]
  res = 0.0
  for i in range(dim_hidden):
    res += math.log(scale_b[i]/scale_a[i]) + (scale_a[i]*scale_a[i] + (loc_a[i]-loc_b[i])*(loc_a[i]-loc_b[i]))/2/scale_b[i]/scale_b[i] - 0.5
  return res
  
if __name__ == "__main__":
  main(get_args())
